{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUqMQnflu6gk"
   },
   "source": [
    "## Requirements \n",
    "* (done) Apply **mini-batch gradient descent** with appropriate batch size\n",
    "* (tweak) Use appropriate **learning rate** (can be adaptive per epoch)\n",
    "* (tweak) Apply **dropout** - find appropriate dropout rate at each layer\n",
    "* (tweak) Initialize random **weights** properly before training\n",
    "* (done) Do basic image **augmentation** of training data using Keras\n",
    "* (done) Use **3 or more layers** with appropriate **number of neurons** per layer\n",
    "* (done) Use **relu activation layer** in the right places\n",
    "* (done) **Normalize and scale** the input before training with Keras\n",
    "* (todo) Include **metrics**: testing, training accuracy validation curves and confusion matrix\n",
    "* (todo) Display top common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h46hwvalkXY3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[0:2000]\n",
    "y_train = y_train[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(x_train[3][:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset augmentation\n",
    "\n",
    "Using Keras Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_augmented = x_train[0:500]\n",
    "y_train_augmented = y_train[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_augmented = x_train_augmented.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 28, 28, 1)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment 1k training dataset images\n",
    "# Reference: https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use datagen.flow to obtain the entire batch at once and prepend to original dataset.\n",
    "x_train2 = None\n",
    "for x_batch, y_batch in datagen.flow(x_train_augmented, y_train_augmented, batch_size=len(x_train_augmented)):\n",
    "    x_train2 = x_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape the augmented dataset into (num_instances, width, height)\n",
    "x_train_augmented = x_train2.reshape(len(x_train_augmented), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0:500] = x_train_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(x_train_augmented[3][:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above two images look the same.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(x_train_augmented[5], x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like Keras datagen actually did some augmentation. Not enough to be visible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalization\n",
    "The training data is 1 3D array of (digit_label, pixel width, pixel height). For our MLP to run gradient descent, the width and height must be converted into a vector of 784 pixels.\n",
    "\n",
    "This is accomplished using numpy's reshape() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "# Scale input (examples, width, height) --> (examples, width*height)\n",
    "x_train = x_train.reshape((x_train.shape[0], num_pixels)).astype('float32')\n",
    "x_test = x_test.reshape((x_test.shape[0], num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values from 0-255 to 0-1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode the labels\n",
    "\n",
    "One hot encoding essentially transforms the categorical values into a matrix where their existence or absence is marked by 1 or 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions\n",
    "\n",
    "* Relu\n",
    "* Mini-batch gradient descent based train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TApeoxxEkY-r"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x >= 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vehw6MM7q-8j"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Runs a 3 layer mini batch gradient descent \n",
    "\n",
    "@ params: images\n",
    "@ retval: void\n",
    "''' \n",
    "def train(images, labels, test_images, test_labels):\n",
    "    batch_size = 100\n",
    "\n",
    "    alpha, iterations = (0.0009, 64)\n",
    "    \n",
    "    # MNIST dataset specific settings and hidden layer neuron size\n",
    "    pixels_per_image, num_labels, hidden_size = (784, 10, 100)\n",
    "\n",
    "    # Weight initialization for various layers -- # of neurons based on the tuple passed to np.random\n",
    "    weights_0_1 = 0.2 * np.random.random((pixels_per_image, hidden_size*2)) - 0.1\n",
    "    weights_1_2 = 0.2 * np.random.random((hidden_size*2, hidden_size)) - 0.1\n",
    "    weights_2_3 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
    "    \n",
    "    for j in range(iterations):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "      \n",
    "        for i in range(int(len(images) / batch_size)):\n",
    "            batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
    "\n",
    "            layer_0 = images[batch_start:batch_end]\n",
    "            \n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "            l1_dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "            layer_1 *= l1_dropout_mask * 2\n",
    "            \n",
    "            layer_2 = relu(np.dot(layer_1, weights_1_2))\n",
    "            l2_dropout_mask = np.random.randint(2, size=layer_2.shape)\n",
    "            layer_2 *= l2_dropout_mask * 2\n",
    "            \n",
    "            layer_3 = np.dot(layer_2, weights_2_3)\n",
    "\n",
    "            error += np.sum((labels[batch_start:batch_end] - layer_3) ** 2)\n",
    "            for k in range(batch_size):\n",
    "                correct_cnt += int(np.argmax(layer_2[k:k+1])) == np.argmax(labels[batch_start+k:batch_start+k+1])\n",
    "\n",
    "                layer_3_delta = (labels[batch_start:batch_end] - layer_3) / batch_size\n",
    "                layer_2_delta = layer_3_delta.dot(weights_2_3.T) * relu2deriv(layer_2)\n",
    "                layer_2_delta *= l2_dropout_mask\n",
    "                layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "                layer_1_delta *= l1_dropout_mask\n",
    "\n",
    "                weights_2_3 += alpha * layer_2.T.dot(layer_3_delta)\n",
    "                weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "                weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "        if(j%10 == 0):\n",
    "            test_error = 0.0\n",
    "            test_correct_cnt = 0\n",
    "\n",
    "            for i in range(len(test_images)):\n",
    "                layer_0 = test_images[i:i+1]\n",
    "                layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "                layer_2 = relu(np.dot(layer_1, weights_1_2))\n",
    "                layer_3 = relu(np.dot(layer_2, weights_2_3))\n",
    "\n",
    "                test_error += np.sum((test_labels[i:i+1] - layer_3) ** 2)\n",
    "                test_correct_cnt += int(np.argmax(layer_3) == \\\n",
    "                                         np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "            sys.stdout.write(\"\\n\" + \\\n",
    "            \"I:\" + str(j) + \\\n",
    "            \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
    "            \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
    "            \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
    "            \" Train-Acc:\" + str(correct_cnt/ float(len(images))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.876 Test-Acc:0.2221 Train-Err:1.176 Train-Acc:0.013\n",
      "I:10 Test-Err:0.732 Test-Acc:0.6997 Train-Err:0.820 Train-Acc:0.0085\n",
      "I:20 Test-Err:0.637 Test-Acc:0.7616 Train-Err:0.758 Train-Acc:0.011\n",
      "I:30 Test-Err:0.581 Test-Acc:0.798 Train-Err:0.724 Train-Acc:0.0085\n",
      "I:40 Test-Err:0.555 Test-Acc:0.8079 Train-Err:0.696 Train-Acc:0.0045"
     ]
    }
   ],
   "source": [
    "train(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "### Training\n",
    "\n",
    "### Testing\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "### Most common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Asg1_graded.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
