{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Adam, SGD\n",
    "from torch import optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"./mnist\"\n",
    "print(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define LeNet 5 which contains 5 layers -- 2 convolution and 3 fully connected dense layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.conv_2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.fc_1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc_2   = nn.Linear(120, 84)\n",
    "        self.fc_3   = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv_1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv_2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(base_dir + '/train.csv').values\n",
    "test = pd.read_csv(base_dir + '/test.csv').values\n",
    "pd.read_csv(base_dir + '/train.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process -- convert data into correct size and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Converting data\n",
      "torch.Size([42000, 1, 28, 28]) torch.Size([42000, 1])\n"
     ]
    }
   ],
   "source": [
    "print (\"2. Converting data\")\n",
    "trainX  = train[:, 1:].reshape(train.shape[0], 1, 28, 28)\n",
    "trainX  = trainX.astype(float)\n",
    "trainX /= 255.0\n",
    "trainX  = torch.from_numpy(trainX);\n",
    "trainY = train[:,0];\n",
    "trainY = trainY.astype(int);\n",
    "trainY = torch.from_numpy(trainY);\n",
    "trainY = trainY.view(train.shape[0],-1);\n",
    "print (trainX.size(), trainY.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 50\n",
    "pyplot.imshow(x_train.cpu()[index].reshape((28, 28)), cmap=\"gray\")\n",
    "print(trainY[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "net = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = train.shape[0]\n",
    "epoch = 75000\n",
    "index_v = 0\n",
    "batch_size = 4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2000, Loss = 2.262963\n",
      "Epoch = 4000, Loss = 2.239201\n",
      "Epoch = 6000, Loss = 1.794622\n",
      "Epoch = 8000, Loss = 1.098259\n",
      "Epoch = 10000, Loss = 0.417671\n",
      "Epoch = 12000, Loss = 0.377651\n",
      "Epoch = 14000, Loss = 0.010643\n",
      "Epoch = 16000, Loss = 0.016616\n",
      "Epoch = 18000, Loss = 0.304940\n",
      "Epoch = 20000, Loss = 0.037759\n",
      "Epoch = 22000, Loss = 0.014095\n",
      "Epoch = 24000, Loss = 0.007249\n",
      "Epoch = 26000, Loss = 0.052577\n",
      "Epoch = 28000, Loss = 0.007794\n",
      "Epoch = 30000, Loss = 0.304937\n",
      "Epoch = 32000, Loss = 0.005952\n",
      "Epoch = 34000, Loss = 0.032157\n",
      "Epoch = 36000, Loss = 0.036868\n",
      "Epoch = 38000, Loss = 0.121651\n",
      "Epoch = 40000, Loss = 0.005932\n",
      "Epoch = 42000, Loss = 0.050617\n",
      "Epoch = 44000, Loss = 0.006924\n",
      "Epoch = 46000, Loss = 0.021020\n",
      "Epoch = 48000, Loss = 0.006283\n",
      "Epoch = 50000, Loss = 0.120847\n",
      "Epoch = 52000, Loss = 0.025698\n",
      "Epoch = 54000, Loss = 0.017460\n",
      "Epoch = 56000, Loss = 0.000283\n",
      "Epoch = 58000, Loss = 0.002351\n",
      "Epoch = 60000, Loss = 0.117294\n",
      "Epoch = 62000, Loss = 0.000581\n",
      "Epoch = 64000, Loss = 0.008483\n",
      "Epoch = 66000, Loss = 0.000408\n",
      "Epoch = 68000, Loss = 0.005859\n",
      "Epoch = 70000, Loss = 0.002700\n",
      "Epoch = 72000, Loss = 0.105266\n",
      "Epoch = 74000, Loss = 0.002662\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(tot_epoch):\n",
    "    if index_v + batch_size >= train_t:\n",
    "        index_v = 0\n",
    "    else:\n",
    "        index_v = index_v + batch_size\n",
    "    # Fetch Data and Labels\n",
    "    data  = Variable(trainX[index_v:(index_v+batch_size)].clone())\n",
    "    label = Variable(trainY[index_v:(index_v+batch_size)].clone(), requires_grad = False)\n",
    "    # Convert data to pytorch objects\n",
    "    data  = data.type(torch.FloatTensor)\n",
    "    label = label.type(torch.LongTensor)\n",
    "    if use_gpu:\n",
    "        data  = data.cuda()\n",
    "        label = label.cuda()\n",
    "    # Do the learning through backprop using the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    out   = net(data)\n",
    "    label = label.view(batch_size)\n",
    "    loss  = criterion(out, label)\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "    if (epoch + 1) % 2000 == 0:\n",
    "        print(\"Epoch = %d, Loss = %f\" %(epoch+1, mini_loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the test data\n",
    "Y_data  = test.reshape(test.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data);\n",
    "print (Y_data.size())\n",
    "nb_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tested = 2000\n",
      "Total tested = 4000\n",
      "Total tested = 6000\n",
      "Total tested = 8000\n",
      "Total tested = 10000\n",
      "Total tested = 12000\n",
      "Total tested = 14000\n",
      "Total tested = 16000\n",
      "Total tested = 18000\n",
      "Total tested = 20000\n",
      "Total tested = 22000\n",
      "Total tested = 24000\n",
      "Total tested = 26000\n",
      "Total tested = 28000\n"
     ]
    }
   ],
   "source": [
    "pred_final = np.ndarray(shape = (nb_test, 2), dtype=int)\n",
    "for i in range(nb_test):\n",
    "    # Convert and load test data\n",
    "    sample_data = Variable(Y_data[i:i+1].clone())\n",
    "    sample_data = sample_data.type(torch.FloatTensor)\n",
    "    if use_gpu:\n",
    "        sample_data = sample_data.cuda()\n",
    "    sample_out = net(sample_data)\n",
    "    # Get the max probabilities \n",
    "    _, pred = torch.max(sample_out, 1)\n",
    "    pred_final[i][0] = 1 + i\n",
    "    pred_final[i][1] = pred.data[0]\n",
    "    if (i + 1) % 2000 == 0:\n",
    "        print(\"Total tested = %d\" %(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
