{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFsLGIccgcUN",
        "colab_type": "text"
      },
      "source": [
        "### Manmeet Singh 013906919\n",
        "\n",
        "Assignment 2 Part I: Write autodiff python library and based on it, do  mnist classifier (similar to last exercise but using autodiff library  that you will write instead of direct numpy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLlw0e91pP_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jan9vLLgglK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4EbnCO3pS9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5M2S1WpVRG",
        "colab_type": "code",
        "outputId": "2f6d5818-5212-45cc-8d39-5520438f94e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiNXl8uHun0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tensor():\n",
        "\n",
        "    def __init__(self, data, requires_grad=False):\n",
        "        self.data = data\n",
        "        if not isinstance(data, np.ndarray):\n",
        "            self.data = np.array(data)\n",
        "        # whether to run backpropagation or not\n",
        "        self.requires_grad = requires_grad\n",
        "        # tensor gradient\n",
        "        self._grad = None\n",
        "        # operation if this tensor was used in it\n",
        "        self._grad_fn = None\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.data.shape\n",
        "\n",
        "    @property\n",
        "    def grad_fn(self):\n",
        "        if not self.requires_grad:\n",
        "            raise Exception('This tensor is not backpropagated')\n",
        "        return self._grad_fn\n",
        "\n",
        "    @property\n",
        "    def grad(self):\n",
        "        return self._grad\n",
        "\n",
        "    def backward(self, grad=None):\n",
        "        if not self.grad_fn:\n",
        "            return False\n",
        "\n",
        "        if grad is None and self._grad is None:\n",
        "            # in case if this is last loss tensor\n",
        "            grad = self.__class__(1., requires_grad=False)\n",
        "\n",
        "        elif self.grad is not None:\n",
        "            grad = self._grad\n",
        "\n",
        "        if not self.requires_grad:\n",
        "            raise Exception('This tensor is not backpropagated')\n",
        "\n",
        "        self.grad_fn.backward(grad)\n",
        "        return True\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'Tensor({str(self.data)})'\n",
        "\n",
        "    def add_grad(self, grad):\n",
        "        if self._grad is None:\n",
        "            self._grad = grad\n",
        "        else:\n",
        "            self._grad += grad\n",
        "\n",
        "    def __add__(self, o): \n",
        "        if self.data is not None:\n",
        "            self.data += o.data  \n",
        "            return self\n",
        "        self.data = o.data \n",
        "        return self\n",
        "\n",
        "class Op():\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def backward(self, grad):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        self.out = self.forward(*args)\n",
        "        self.out._grad_fn = self\n",
        "        return self.out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKDJ_wUIoL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AddOp(Op):\n",
        "\n",
        "    '''Sumation operation with 2 tensors'''\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        # created tensor should be backpropagated if at least one \n",
        "        # of the input is backpropagated\n",
        "        requires_grad = x.requires_grad or y.requires_grad\n",
        "        return Tensor(x.data + y.data, requires_grad=requires_grad)\n",
        "\n",
        "    def backward(self, grad):\n",
        "        if self.x.requires_grad:\n",
        "            # as we have matrix operation one of the parameters can have partial shape\n",
        "            # in such scenarion we need to sum gradient values by missed axis\n",
        "            if self.x.shape != grad.shape:\n",
        "                axis = np.argmax(np.abs(np.array(self.x.shape) - np.array(grad.shape)))\n",
        "                self.x.add_grad(Tensor(grad.data.sum(axis=axis, keepdims=True)))\n",
        "            else:\n",
        "                self.x.add_grad(grad)\n",
        "            if self.x.grad_fn:\n",
        "                self.x.backward()\n",
        "        if self.y.requires_grad:\n",
        "            if self.y.shape != grad.shape:\n",
        "                axis = np.argmax(np.abs(np.array(self.y.shape) - np.array(grad.shape)))\n",
        "                self.y.add_grad(Tensor(grad.data.sum(axis=axis, keepdims=True)))\n",
        "            else:\n",
        "                self.y.add_grad(grad)\n",
        "            if self.y.grad_fn:\n",
        "                self.y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx5C1FUSIuAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MulOp(Op):\n",
        "\n",
        "    '''Multiplication operation with 2 tensors'''\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        requires_grad = x.requires_grad or y.requires_grad\n",
        "        return Tensor(x.data * y.data, requires_grad=requires_grad)\n",
        "\n",
        "    def backward(self, grad):\n",
        "        if self.x.requires_grad:\n",
        "            self.x.add_grad(Tensor(grad.data * self.y.data, False))\n",
        "            if self.x.grad_fn:\n",
        "                self.x.backward()\n",
        "        if self.y.requires_grad:\n",
        "            self.y.add_grad(Tensor(grad.data * self.x.data, False))\n",
        "            if self.y.grad_fn:\n",
        "                self.y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmWNgphCQ3se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer():\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplemented\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        return self.forward(*args)\n",
        "\n",
        "class Sigmoid():\n",
        "\n",
        "    def forward(self,x):\n",
        "        self.x = x   \n",
        "        return 1/(1+np.exp(-x))\n",
        "      \n",
        "    def backward(self, grad):\n",
        "        grad_input = self.x*(1-self.x) * grad\n",
        "        return grad_input\n",
        "\n",
        "class Relu(Layer):\n",
        "\n",
        "    def forward(self,x):\n",
        "        self.x = x\n",
        "        return np.maximum(np.zeros_like(x), x)\n",
        "      \n",
        "    def backward(self, grad):\n",
        "        grad_input = (self.x > 0) * grad\n",
        "        return grad_input\n",
        "\n",
        "class SoftmaxCrossentropyWithLogits(Layer):\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        exps = np.exp(x) \n",
        "        self.softmax = exps / np.sum(exps, axis=-1, keepdims=True)\n",
        "\n",
        "        logits = self.softmax[np.arange(x.shape[0]),y]\n",
        "        log_likelihood = -np.log(logits)\n",
        "        loss = np.sum(log_likelihood) / x.shape[0]\n",
        "        return loss\n",
        "      \n",
        "    def backward(self, grad=None):\n",
        "        batch = self.x.shape[0]\n",
        "        grad = self.softmax\n",
        "        grad[np.arange(batch),self.y] -= 1\n",
        "        grad = grad/batch\n",
        "        return grad\n",
        "\n",
        "class MSE(Layer):\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        return ((x - y)**2) / (self.x.shape[0]*2)\n",
        "\n",
        "    def backward(self, grad=None):\n",
        "        # 1/2n * Sum(xi-yi)**2 \n",
        "        # dx = 1/2n * Sum( x**2 -2*x*y + y**2) \n",
        "        # dx  = (2x - 2y) / 2*n = (x - y) / n\n",
        "        return (self.x - self.y) / self.x.shape[0]\n",
        "\n",
        "class Linear(Layer):\n",
        "\n",
        "    def __init__(self, input, output, lr=0.0001):\n",
        "        self.A = 2*np.random.random((input, output)) - 1\n",
        "        self.b = 2*np.random.random((output)) - 1\n",
        "        self.lr = lr\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x,self.A) + self.b\n",
        "\n",
        "    def backward(self, grad):\n",
        "        # d_layer / db = 1\n",
        "        b_grad = grad.mean(axis=0)*self.x.shape[0]\n",
        "        # d_layer / dA = x\n",
        "        A_grad = np.dot(self.x.T, grad)\n",
        "        # As this layer have somee weights we need to update them using \n",
        "        # gradient descent\n",
        "        # compute df / dx = df / d_layer * d_layer / dx\n",
        "        # df / d_layer == grad\n",
        "        grad_input = np.dot(grad, self.A.T)\n",
        "        \n",
        "        self.A -= A_grad * self.lr\n",
        "        self.b -= b_grad * self.lr\n",
        "\n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUKdYMniIYk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(Layer):\n",
        "\n",
        "    def __init__(self, lr=0.0001):\n",
        "        self.lr = lr\n",
        "        self.layers = [\n",
        "            Linear(3,15, lr=self.lr),\n",
        "            Relu(),\n",
        "            Linear(15,1, lr=self.lr)        \n",
        "        ]\n",
        "\n",
        "    def forward(self,x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        for l in self.layers[::-1]:\n",
        "            grad = l.backward(grad)\n",
        "\n",
        "        return grad\n",
        "\n",
        "mm = Model()\n",
        "\n",
        "def yf(x1,x2,x3):\n",
        "    return np.array([2 * x1 + 3*x2 + 4*x3 + 5],dtype=np.float32)\n",
        "\n",
        "loss = MSE()\n",
        "\n",
        "for i in range(20000):\n",
        "    x1 = np.random.random()*30\n",
        "    x2 = np.random.random()*20\n",
        "    x3 = np.random.random()*11\n",
        "    y = mm(np.array([[x1,x2,x3]]))\n",
        "    err = loss(y, yf(x1,x2,x3))\n",
        "    \n",
        "    yb = loss.backward()\n",
        "    yb = mm.backward(yb)\n",
        "    if i % 100 == 0:\n",
        "        print(err)\n",
        "        print('VAL Target:',yf(1,2,3), 'Res:',mm(np.array([[1,2,3]])), 'Loss:',loss(yf(1,2,3), mm(np.array([[1,2,3]]))))\n",
        "        print('---------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xda9zBiCEUqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "25842db6-e404-44d7-dd79-bf750a4cb9a0"
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(y_train[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBl5FiSGEewb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "8b0c4566-4903-452e-961e-b7fb8aae6d8b"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(X_train[0], cmap='gray', interpolation='none')\n",
        "plt.title(\"Digit: {}\".format(y_train[0]))\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.subplot(2,1,2)\n",
        "plt.hist(X_train[0].reshape(784))\n",
        "plt.title(\"Pixel Value Distribution\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Pixel Value Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY_5cNaJGWzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "a1debf0f-d105-4b8d-f884-0d7cadc5c13e"
      },
      "source": [
        "# Shape before we reshape and normalize\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)\n",
        "\n",
        "# build the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize the data\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# print the final input shape\n",
        "print(\"Train matrix shape\", X_train.shape)\n",
        "print(\"Test matrix shape\", X_test.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n",
            "Train matrix shape (60000, 784)\n",
            "Test matrix shape (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PjmdKUSIc4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Model(Layer):\n",
        "\n",
        "    def __init__(self, lr=0.00001):\n",
        "        self.lr = lr\n",
        "        self.layers = [\n",
        "            Linear(784,100, lr=self.lr),\n",
        "            Relu(),\n",
        "            Linear(100,200, lr=self.lr),\n",
        "            Relu(),\n",
        "            Linear(200,10, lr=self.lr)        \n",
        "        ]\n",
        "\n",
        "    def forward(self,x):\n",
        "        for l in self.layers:\n",
        "            x = l(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        for l in self.layers[::-1]:\n",
        "            grad = l.backward(grad)\n",
        "\n",
        "        return grad\n",
        "\n",
        "\n",
        "simple = transforms.Compose([\n",
        "    transforms.ToTensor(), # converts to [0,1] interval\n",
        "])\n",
        "ds = MNIST('./mnist', download=True, transform=simple)\n",
        "ld = DataLoader(ds, batch_size=2, pin_memory=True, drop_last=True) \n",
        "\n",
        "mm = Model()\n",
        "loss = SoftmaxCrossentropyWithLogits()\n",
        "_loss_avg = 0 \n",
        "for e in range(7):\n",
        "    for i, (img, label) in enumerate(ld):\n",
        "        x = img.view(2,-1).numpy()\n",
        "\n",
        "        res = mm(x)\n",
        "        _loss = loss(res, label.numpy())\n",
        "        _loss_avg += _loss.mean() # running loss mean\n",
        "        grad = loss.backward(1)\n",
        "        mm.backward(grad)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(_loss_avg/100)\n",
        "            _loss_avg = 0\n",
        "            print('---------')\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
